[![DOI](https://zenodo.org/badge/688424111.svg)](https://zenodo.org/badge/latestdoi/688424111)

# DiT Text Detection Accelerator

## Overview:
The DiT Text Detection Accelerator is a machine learning (ML) backend service designed to enhance the efficiency of text detection tasks within the Label Studio platform. By leveraging the powerful DiT (Detection in Transformers) model, this service automates the annotation process, reducing the manual effort required from users and ensuring more accurate and rapid text detection in various applications.

## Key Features:

* `DiT Model Integration`: The service seamlessly integrates the DiT model, a state-of-the-art transformer-based architecture specifically designed for text detection tasks. This model is capable of recognizing and locating text within images with exceptional accuracy.

* `Predictive Annotation`: Leveraging the DiT model's capabilities, the service generates predictions for text regions in images. These predictions serve as suggested annotations for users, significantly speeding up the annotation process.

* `Customizable Confidence Threshold`: Users can customize the confidence threshold for predicted annotations, allowing them to control the level of automation and fine-tune the results according to their specific requirements.

* `Scalability`: The ML backend is designed to handle large-scale datasets and can efficiently process a high volume of text detection tasks, making it suitable for both small projects and enterprise-level applications.

* `API Integration`: The service provides a user-friendly API that seamlessly integrates with Label Studio. Users can easily connect their Label Studio projects to the DiT Text Detection Accelerator to access automated text detection capabilities.

* `Annotation Review`: The service includes a user interface for reviewing and confirming automated annotations. This ensures the quality and accuracy of the annotations generated by the DiT model.

## Benefits:

* `Time Savings`: By automating the text detection process, users can significantly reduce the time and effort required for annotation, allowing them to focus on more critical aspects of their projects.

* `Improved Accuracy`: The DiT model's high accuracy ensures that automated predictions are reliable, minimizing the need for manual corrections.

* `Enhanced Productivity`: The accelerated annotation process increases overall productivity, enabling users to complete tasks more efficiently.

* `Flexibility`: Users can adapt the service to their specific needs by adjusting the confidence threshold and reviewing automated annotations as desired.

## Use Cases:

* `Document Digitization`: Streamline the process of converting printed or handwritten text in documents into digital formats.
* `Image-based Text Extraction`: Efficiently extract text from images for applications such as OCR (Optical Character Recognition).
* `Text Annotation for Computer Vision`: Accelerate the labeling of text regions in images for training computer vision models.

The DiT Text Detection Accelerator is a valuable addition to Label Studio, enhancing text detection capabilities and making the annotation process more efficient and accurate. It empowers users to tackle text-related tasks with confidence, saving time and resources while achieving high-quality results.

# Quick usage

For quick usage run docker-compose in your working directory:

```bash
docker-compose up -d
```

> *Note*: You have to insert S3 authentication in docker-compose.yml starting from the template.
> 
> For enabling GPU access with Compose, see [link](https://docs.docker.com/compose/gpu-support/).


# Reference to tutorial

See the tutorial in the documentation for building your own image and advanced usage:

https://github.com/heartexlabs/label-studio/blob/master/docs/source/tutorials/object-detector.md

## Citation

```
@misc{li2022dit,
    title={DiT: Self-supervised Pre-training for Document Image Transformer},
    author={Junlong Li and Yiheng Xu and Tengchao Lv and Lei Cui and Cha Zhang and Furu Wei},
    year={2022},
    eprint={2203.02378},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```
